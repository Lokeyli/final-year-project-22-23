{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaeedeaa",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "7d9f6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from sys import __stdout__\n",
    "from ast import literal_eval\n",
    "from pickle import dump\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import copy\n",
    "from pandas import DataFrame\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from typing import Dict, Set, Tuple, List, Any, Optional, Callable\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils # type: ignore\n",
    "mp_drawing_styles = mp.solutions.drawing_styles # type: ignore\n",
    "mp_face_mesh = mp.solutions.face_mesh # type: ignore\n",
    "mp_face_mesh_connections = mp.solutions.face_mesh_connections # type: ignore\n",
    "\n",
    "from settings import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e61b626",
   "metadata": {},
   "source": [
    "## Prepare the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "01971d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lokeyli/Documents/Unity/Unity-Web-socket/index67-weight$0.png\n",
      "File not found\n"
     ]
    }
   ],
   "source": [
    "BLENDSHAPE_I = []\n",
    "WEIGHTS = []\n",
    "IMAGE_FILES = []\n",
    "\n",
    "csv_file = open(BLENDSHAPE_FILE, \"r\")\n",
    "reader = csv.reader(csv_file, skipinitialspace=True, delimiter=\",\")\n",
    "## skip header\n",
    "next(reader, None)\n",
    "for line in reader:\n",
    "    if not Path(line[2]).exists():\n",
    "        print(line[2])\n",
    "        print(\"File not found\")\n",
    "        continue\n",
    "    BLENDSHAPE_I.append(line[0])\n",
    "    WEIGHTS.append(line[1])\n",
    "    IMAGE_FILES.append(line[2])\n",
    "csv_file.close()\n",
    "\n",
    "train_file = open(TRAIN_FILE, \"w\")\n",
    "writer = csv.writer(train_file, delimiter=\",\", quoting=csv.QUOTE_ALL)\n",
    "writer.writerow(HEADERS)\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    ") as face_mesh:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print and draw face mesh landmarks on the image.\n",
    "        if not results.multi_face_landmarks:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        arr = [BLENDSHAPE_I[idx], WEIGHTS[idx]]\n",
    "\n",
    "        # Assume to have only one face in tracking, \n",
    "        # Following is equal to results.multi_face_landmarks[0]\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                arr.append([landmark.x, landmark.y, landmark.z])\n",
    "            writer.writerow(arr)\n",
    "train_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afdd7c5d",
   "metadata": {},
   "source": [
    "## Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "2ef3c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blendshape_idx_lst = []\n",
    "pipelines: Dict[str, Pipeline] = dict()\n",
    "models: Dict[str, Callable]  = dict()\n",
    "selection_methods: Dict[str, Callable] = dict()\n",
    "training_set_transformers: Dict[str, Callable] = dict()\n",
    "\n",
    "class BlendshapeData:\n",
    "    def __init__(self, train_X, test_X, train_Y, test_Y) -> None:\n",
    "        self.train_X = train_X\n",
    "        self.test_X = test_X\n",
    "        self.train_Y = train_Y\n",
    "        self.test_Y = test_Y\n",
    "\n",
    "def default_split(X, Y) -> BlendshapeData:\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "            X, Y, test_size=0.2, random_state=42, shuffle=True\n",
    "        )\n",
    "    return BlendshapeData(train_X, test_X, train_Y, test_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "60ab279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def __init__(self, pipeline_name: str, \n",
    "                dataset_transformer: Callable, \n",
    "                model: Callable,\n",
    "                split: Callable,\n",
    "                selection_method: Optional[Callable] = None) -> None:\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.dataset_transformer = dataset_transformer\n",
    "        self.selection_method = selection_method\n",
    "        self.model = model\n",
    "        self.split = split\n",
    "    \n",
    "    def fit(self, train_df: DataFrame):\n",
    "        selectors = dict()\n",
    "        predictors = dict()\n",
    "        results = []\n",
    "        transformed_df = self.dataset_transformer(train_df)\n",
    "        for blendshape_i in blendshape_idx_lst:\n",
    "            sub_df = transformed_df[transformed_df[\"blendshape_i\"] == blendshape_i]\n",
    "            reduced_X = sub_df.iloc[:, 2:]\n",
    "            Y = sub_df.filter(regex=\"weight\").to_numpy().flatten()\n",
    "            selectors[f\"{blendshape_i}\"] = None\n",
    "            if self.selection_method:\n",
    "                predictor = self.selection_method(reduced_X, Y)\n",
    "                reduced_X = predictor.fit_transform(reduced_X, Y)\n",
    "                selectors[f\"{blendshape_i}\"] = copy.deepcopy(predictor)\n",
    "            splitted_data = self.split(reduced_X, Y)\n",
    "            self.model.fit(splitted_data.train_X, splitted_data.train_Y)\n",
    "            score = self.model.score(splitted_data.test_X, splitted_data.test_Y)\n",
    "            results.append(score)\n",
    "            predictors[f\"{blendshape_i}\"] = copy.deepcopy(self.model)\n",
    "            # print(f\"{self.pipeline_name}: blendshape_i={blendshape_i}, score={score}\")\n",
    "        print(f\"{self.pipeline_name}: mean={np.mean(results)}, min={np.min(results)}, max={np.max(results)}\")\n",
    "        return selectors, predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "615c0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    TRAIN_FILE, header=0, names=HEADERS, delimiter=\",\", index_col=False\n",
    ")\n",
    "blendshape_idx_lst = train_df[\"blendshape_i\"].drop_duplicates().to_list()\n",
    "landmarks = train_df.columns[2:].to_list()\n",
    "train_df[landmarks] = train_df[landmarks].applymap(literal_eval).applymap(np.array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "7bef35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]\n"
     ]
    }
   ],
   "source": [
    "print(blendshape_idx_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b2bb745",
   "metadata": {},
   "source": [
    "### Generating different training sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ead703dd",
   "metadata": {},
   "source": [
    "#### Default training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "67a46625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_set(input_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Produce the training set that using 478 landmarks' coordinates (1434 in total) as features\n",
    "\n",
    "    Args:\n",
    "        input_df (DataFrame): the origin dataframe from csv file\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: the training set with distance between landmarks\n",
    "    \"\"\"\n",
    "    default_train_columns = (input_df.columns[:2].to_list()\n",
    "        + [f\"{i}_landmark_{j}\" for i in range(N_LANDMARKS) for j in [\"x\", \"y\", \"z\"]])\n",
    "\n",
    "    default_train_data =[]\n",
    "\n",
    "    for i, row in input_df.iterrows():\n",
    "        val = row.values\n",
    "        new_row = val[:2]\n",
    "        new_row = np.append(new_row, np.concatenate(val[2:]))\n",
    "        default_train_data.append(new_row)\n",
    "    default_training_set = DataFrame(data=default_train_data, columns=default_train_columns)\n",
    "    return default_training_set\n",
    "training_set_transformers[\"default\"] = default_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5911c74",
   "metadata": {},
   "source": [
    "#### Distance training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "db0383d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_set(input_df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Produce the training set with distance between certain sets of landmarks\n",
    "\n",
    "    Args:\n",
    "        input_df (DataFrame): the origin dataframe from csv file\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: the training set with distance between landmarks\n",
    "    \"\"\"\n",
    "    vertices_sets: Dict[str, Set[Tuple[int, int]]] = {\n",
    "        \"FACEMESH_FACE_OVAL\": mp_face_mesh_connections.FACEMESH_FACE_OVAL,\n",
    "        \"FACEMESH_LIPS\": mp_face_mesh_connections.FACEMESH_LIPS, \n",
    "        \"FACEMESH_LEFT_EYE\": mp_face_mesh_connections.FACEMESH_LEFT_EYE,\n",
    "        \"FACEMESH_LEFT_IRIS\": mp_face_mesh_connections.FACEMESH_LEFT_IRIS,\n",
    "        \"FACEMESH_LEFT_EYEBROW\": mp_face_mesh_connections.FACEMESH_LEFT_EYEBROW,\n",
    "        \"FACEMESH_RIGHT_EYE\": mp_face_mesh_connections.FACEMESH_RIGHT_EYE,\n",
    "        \"FACEMESH_RIGHT_EYEBROW\": mp_face_mesh_connections.FACEMESH_RIGHT_EYEBROW,\n",
    "        \"FACEMESH_RIGHT_IRIS\": mp_face_mesh_connections.FACEMESH_RIGHT_IRIS}\n",
    "\n",
    "    # define the column names\n",
    "    distance_train_columns = train_df.columns[:2].to_list()\n",
    "    for name, vertices_set in vertices_sets.items():\n",
    "        for idx, vertices in enumerate(vertices_set):\n",
    "            column = f\"{name}_distance_{idx}\"\n",
    "            distance_train_columns.append(column)\n",
    "\n",
    "    distance_train_data = DataFrame(columns=distance_train_columns, dtype=np.float64)\n",
    "\n",
    "    for i, row in train_df.iterrows():\n",
    "        new_row = list(row.values[:2])\n",
    "        for name, vertices_set in vertices_sets.items():\n",
    "            for idx, vertices in enumerate(vertices_set):\n",
    "                new_row.append(np.linalg.norm(row[vertices[0] + 2] - row[vertices[1] + 2]))\n",
    "        distance_train_data.loc[i] = new_row\n",
    "\n",
    "    # cast the data types in the dataframe\n",
    "    for column in distance_train_columns[:2]:\n",
    "        distance_train_data[column] = distance_train_data[column].fillna(0).astype(int)\n",
    "    \n",
    "    return distance_train_data\n",
    "\n",
    "training_set_transformers[\"distance\"] = distance_set\n",
    "\n",
    "def distance_for_prediction(input_df: DataFrame) -> DataFrame:\n",
    "    vertices_sets: Dict[str, Set[Tuple[int, int]]] = {\n",
    "        \"FACEMESH_FACE_OVAL\": mp_face_mesh_connections.FACEMESH_FACE_OVAL,\n",
    "        \"FACEMESH_LIPS\": mp_face_mesh_connections.FACEMESH_LIPS, \n",
    "        \"FACEMESH_LEFT_EYE\": mp_face_mesh_connections.FACEMESH_LEFT_EYE,\n",
    "        \"FACEMESH_LEFT_IRIS\": mp_face_mesh_connections.FACEMESH_LEFT_IRIS,\n",
    "        \"FACEMESH_LEFT_EYEBROW\": mp_face_mesh_connections.FACEMESH_LEFT_EYEBROW,\n",
    "        \"FACEMESH_RIGHT_EYE\": mp_face_mesh_connections.FACEMESH_RIGHT_EYE,\n",
    "        \"FACEMESH_RIGHT_EYEBROW\": mp_face_mesh_connections.FACEMESH_RIGHT_EYEBROW,\n",
    "        \"FACEMESH_RIGHT_IRIS\": mp_face_mesh_connections.FACEMESH_RIGHT_IRIS}\n",
    "\n",
    "    # define the column names\n",
    "    distance_train_columns = list()\n",
    "    for name, vertices_set in vertices_sets.items():\n",
    "        for idx, vertices in enumerate(vertices_set):\n",
    "            column = f\"{name}_distance_{idx}\"\n",
    "            distance_train_columns.append(column)\n",
    "\n",
    "    distance_train_data = DataFrame(columns=distance_train_columns, dtype=np.float64)\n",
    "\n",
    "    for i, row in input_df.iterrows():\n",
    "        new_row = list()\n",
    "        for name, vertices_set in vertices_sets.items():\n",
    "            for idx, vertices in enumerate(vertices_set):\n",
    "                new_row.append(np.linalg.norm(row[vertices[0]] - row[vertices[1]]))\n",
    "        distance_train_data.loc[0] = new_row # type: ignore\n",
    "    \n",
    "    return distance_train_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a536a68",
   "metadata": {},
   "source": [
    "#### Cartesian product default training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "88d8f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product_default_set(input_df: DataFrame) -> DataFrame:\n",
    "    res_dataframe = DataFrame()\n",
    "    for blendshape_i in blendshape_idx_lst:\n",
    "        dataframe = default_set(input_df)\n",
    "        dataframe.loc[:, 'blendshape_i'] = blendshape_i\n",
    "        if res_dataframe is None:\n",
    "            res_dataframe = dataframe\n",
    "        else:  \n",
    "            res_dataframe = pd.concat([res_dataframe, dataframe], ignore_index=True)\n",
    "    return res_dataframe\n",
    "training_set_transformers[\"cartesian_product_default\"] = cartesian_product_default_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d67a54db",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "861f1e79",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "4ffebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_pca(X, Y) -> PCA:\n",
    "    n: int = min(X.shape)\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X=X, y=Y)\n",
    "    explained_variance_ratios = pca.explained_variance_ratio_ # type: ignore\n",
    "    for i in range(n):\n",
    "        if sum(explained_variance_ratios[:i]) > 0.95:\n",
    "            n = i\n",
    "            break\n",
    "    pca = PCA(n_components=n)\n",
    "    return pca\n",
    "    \n",
    "selection_methods[\"PCA\"] = selection_pca\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7c8c913",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "cd122110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_tsne(X, Y) -> TSNE:\n",
    "    n: int = X.shape[1]\n",
    "    tsne = TSNE(n_components=n)\n",
    "    tsne.fit(X=X, y=Y)\n",
    "    explained_variance_ratios = pca.explained_variance_ratio_ # type: ignore\n",
    "    for i in range(n):\n",
    "        if sum(explained_variance_ratios[:i]) > 0.95:\n",
    "            n = i\n",
    "            break\n",
    "    print(\"TSNE: n_components=\", n)\n",
    "    tsne = TSNE(n_components=n)\n",
    "    return tsne\n",
    "\n",
    "selection_methods[\"TSNE\"] = selection_tsne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab2c514",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33434706",
   "metadata": {},
   "source": [
    "### Ensemble Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "506fc098",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "719c55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"random_forest_regressor\"] = RandomForestRegressor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "415b88df",
   "metadata": {},
   "source": [
    "#### Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "cc5544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"ada_boost_regressor\"] = AdaBoostRegressor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe721b5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "05f82527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines[\"default_random_forest_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"default_random_forest_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"default\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"random_forest_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_random_forest_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_random_forest_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"random_forest_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"default_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"default_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"default\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "pipelines[\"default_pca_ada_boost_regressor\"] = Pipeline(\n",
    "    pipeline_name=\"default_pca_ada_boost_regressor\",\n",
    "    dataset_transformer=training_set_transformers[\"default\"],\n",
    "    selection_method=selection_methods[\"PCA\"],\n",
    "    model=models[\"ada_boost_regressor\"],\n",
    "    split=default_split)\n",
    "pipelines[\"distance_pca_ada_boost_regressor\"] = Pipeline(\n",
    "    pipeline_name=\"distance_pca_ada_boost_regressor\",\n",
    "    dataset_transformer=training_set_transformers[\"distance\"],\n",
    "    selection_method=selection_methods[\"PCA\"],\n",
    "    model=models[\"ada_boost_regressor\"],\n",
    "    split=default_split)\n",
    "# pipelines[\"distance_tsne_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_tsne_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"TSNE\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_tsne_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_tsne_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"TSNE\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "05fc5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_pca_ada_boost_regressor: mean=0.9813951761843915, min=0.8682190943231096, max=0.9941995125205076\n",
      "distance_pca_ada_boost_regressor: mean=0.9829311562654667, min=0.9270581622501624, max=0.9957184001658889\n"
     ]
    }
   ],
   "source": [
    "selectors_groups: Dict[str, Dict[str, Any]] = dict()\n",
    "predictors_groups: Dict[str, Dict[str, Any]] = dict()\n",
    "\n",
    "for pipeline in pipelines.values():\n",
    "    selectors, predictors = pipeline.fit(train_df)\n",
    "    selectors_groups[pipeline.pipeline_name] = selectors\n",
    "    predictors_groups[pipeline.pipeline_name] = predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b8be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b3d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "predictors_group_name default_random_forest_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 114 n_features_in 1434\n",
      "==================================================\n",
      "predictors_group_name default_random_forest_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 114 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 114 n_features_in 1434\n",
      "==================================================\n",
      "predictors_group_name default_random_forest_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 114 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 114 n_features_in 1434\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 67 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 68 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 69 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 70 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 71 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 72 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 73 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 74 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 75 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 76 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 77 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 78 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 79 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 80 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 81 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 82 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 83 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 84 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 85 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 86 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 87 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 88 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 89 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 90 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 91 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 92 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 93 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 94 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 95 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 96 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 97 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 98 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 99 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 100 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 101 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 102 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 103 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 104 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 105 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 106 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 107 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 108 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 109 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 110 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 111 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 112 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 113 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 114 n_features_in 132\n",
      "==================================================\n",
      "predictors_group_name default_random_forest_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_random_forest_regressor predictor_name 114 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 67 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 68 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 69 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 70 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 71 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 72 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 73 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 74 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 75 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 76 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 77 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 78 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 79 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 80 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 81 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 82 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 83 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 84 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 85 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 86 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 87 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 88 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 89 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 90 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 91 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 92 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 93 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 94 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 95 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 96 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 97 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 98 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 99 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 100 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 101 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 102 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 103 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 104 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 105 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 106 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 107 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 108 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 109 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 110 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 111 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 112 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 113 n_features_in 1434\n",
      "predictors_group_name default_ada_boost_regressor predictor_name 114 n_features_in 1434\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 67 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 68 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 69 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 70 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 71 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 72 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 73 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 74 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 75 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 76 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 77 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 78 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 79 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 80 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 81 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 82 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 83 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 84 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 85 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 86 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 87 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 88 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 89 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 90 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 91 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 92 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 93 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 94 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 95 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 96 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 97 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 98 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 99 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 100 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 101 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 102 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 103 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 104 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 105 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 106 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 107 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 108 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 109 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 110 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 111 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 112 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 113 n_features_in 132\n",
      "predictors_group_name distance_random_forest_regressor predictor_name 114 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 67 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 68 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 69 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 70 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 71 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 72 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 73 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 74 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 75 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 76 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 77 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 78 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 79 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 80 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 81 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 82 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 83 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 84 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 85 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 86 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 87 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 88 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 89 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 90 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 91 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 92 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 93 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 94 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 95 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 96 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 97 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 98 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 99 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 100 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 101 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 102 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 103 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 104 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 105 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 106 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 107 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 108 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 109 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 110 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 111 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 112 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 113 n_features_in 132\n",
      "predictors_group_name distance_ada_boost_regressor predictor_name 114 n_features_in 132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m blendshape_data \u001b[39min\u001b[39;00m data:\n\u001b[0;32m---> 13\u001b[0m     model\u001b[39m.\u001b[39;49mfit(blendshape_data\u001b[39m.\u001b[39;49mtrain_X, blendshape_data\u001b[39m.\u001b[39;49mtrain_Y)\n\u001b[1;32m     14\u001b[0m     score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mscore(blendshape_data\u001b[39m.\u001b[39mtest_X, blendshape_data\u001b[39m.\u001b[39mtest_Y)\n\u001b[1;32m     15\u001b[0m     \u001b[39m# print(\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m#     f\"{model.__class__.__name__}_blendshape_{blendshape_data.unity_blendshape_i} score: {score}\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    466\u001b[0m ]\n\u001b[1;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    478\u001b[0m )(\n\u001b[1;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    480\u001b[0m         t,\n\u001b[1;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    482\u001b[0m         X,\n\u001b[1;32m    483\u001b[0m         y,\n\u001b[1;32m    484\u001b[0m         sample_weight,\n\u001b[1;32m    485\u001b[0m         i,\n\u001b[1;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1248\u001b[0m         X,\n\u001b[1;32m   1249\u001b[0m         y,\n\u001b[1;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dict that contains the predictors for each training set and model (Cartesian product)\n",
    "# 1 combination per training set and model is called a \"group\"\n",
    "# group name = [train_set_name] + [model_name]\n",
    "# 1 \"group\" contains all the predictors for \"each blendshape\"\n",
    "predictors_groups: Dict[str, Dict[str, Any]] = dict()\n",
    "results: Dict[str, List[int]] = dict()\n",
    "for training_set_name, training_set in training_set_transformers.items():\n",
    "    for model_name, model in models.items():\n",
    "        predictors = dict()\n",
    "        data = prepare_data(training_set(train_df), blendshape_idx_lst)\n",
    "        result = []\n",
    "        for blendshape_data in data:\n",
    "            model.fit(blendshape_data.train_X, blendshape_data.train_Y)\n",
    "            score = model.score(blendshape_data.test_X, blendshape_data.test_Y)\n",
    "            # print(\n",
    "            #     f\"{model.__class__.__name__}_blendshape_{blendshape_data.unity_blendshape_i} score: {score}\"\n",
    "            # )\n",
    "            result.append(score)\n",
    "            predictors[f\"{blendshape_data.unity_blendshape_i}\"] = copy.deepcopy(model)\n",
    "        results[training_set_name + \"_\" + model_name] = result\n",
    "        print(\"=\" * 50)\n",
    "        predictors_groups[training_set_name + \"_\" + model_name] = predictors\n",
    "        for predictors_group_name, predictors_group in predictors_groups.items():\n",
    "            for predictor_name, predictor in predictors_group.items():\n",
    "                print(  \"predictors_group_name\", predictors_group_name, \n",
    "                        \"predictor_name\", predictor_name, \n",
    "                        \"n_features_in\", predictor.n_features_in_)\n",
    "for res in results:\n",
    "    print(f\"{res}: mean={np.mean(results[res])}, min={np.min(results[res])}, max={np.max(results[res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results: Dict[str, List[int]] = dict()\n",
    "for training_set_name, training_set in training_set_transformers.items():\n",
    "    for model_name, model in models.items():\n",
    "        predictors = dict()\n",
    "        data = prepare_data(training_set(train_df), blendshape_idx_lst)\n",
    "        result = []\n",
    "        for blendshape_data in data:\n",
    "            model.fit(blendshape_data.train_X, blendshape_data.train_Y)\n",
    "            score = model.score(blendshape_data.test_X, blendshape_data.test_Y)\n",
    "            # print(\n",
    "            #     f\"{model.__class__.__name__}_blendshape_{blendshape_data.unity_blendshape_i} score: {score}\"\n",
    "            # )\n",
    "            result.append(score)\n",
    "            predictors[f\"{blendshape_data.unity_blendshape_i}\"] = copy.deepcopy(model)\n",
    "        results[training_set_name + \"_\" + model_name] = result\n",
    "        print(\"=\" * 50)\n",
    "        predictors_groups[training_set_name + \"_\" + model_name] = predictors\n",
    "        for predictors_group_name, predictors_group in predictors_groups.items():\n",
    "            for predictor_name, predictor in predictors_group.items():\n",
    "                print(  \"predictors_group_name\", predictors_group_name, \n",
    "                        \"predictor_name\", predictor_name, \n",
    "                        \"n_features_in\", predictor.n_features_in_)\n",
    "for res in results:\n",
    "    print(f\"{res}: mean={np.mean(results[res])}, min={np.min(results[res])}, max={np.max(results[res])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "906bccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97, 30, 71, 50, 7, 5, 78, 12, 36, 8, 4, 3, 10, 5, 6, 2, 22, 20, 4, 14, 4, 38, 4, 17, 13, 2, 19, 3, 2, 11, 3, 29, 2, 10, 5, 26, 21, 21, 19, 14, 70, 23, 17, 10, 20, 9, 72, 8, "
     ]
    }
   ],
   "source": [
    "IMAGE_FILES = [\"/Users/lokeyli/Documents/Unity/Unity-Web-socket/index67-weight$100.png\"]\n",
    "\n",
    "selectors = selectors_groups[\"distance_pca_ada_boost_regressor\"]\n",
    "predictors = predictors_groups[\"distance_pca_ada_boost_regressor\"]\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    ") as face_mesh:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print and draw face mesh landmarks on the image.\n",
    "        if not results.multi_face_landmarks:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        arr = []\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for a in face_landmarks.landmark:\n",
    "                arr.append(np.array([a.x, a.y, a.z]))\n",
    "        predict_df = pd.DataFrame([arr], columns=HEADERS[2:])\n",
    "        for idx, model in predictors.items():\n",
    "            print(int(model.predict(selectors[idx].transform(distance_for_prediction(predict_df)))[0]), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2522c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for selector in selectors_groups[\"distance_pca_ada_boost_regressor\"].values():\n",
    "    print(selector.n_components_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb12b0d5",
   "metadata": {},
   "source": [
    "## Export the ideal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "62477566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector_group {'67': PCA(n_components=2), '68': PCA(n_components=2), '69': PCA(n_components=2), '70': PCA(n_components=2), '71': PCA(n_components=4), '72': PCA(n_components=5), '73': PCA(n_components=4), '74': PCA(n_components=4), '75': PCA(n_components=6), '76': PCA(n_components=5), '77': PCA(n_components=5), '78': PCA(n_components=4), '79': PCA(n_components=4), '80': PCA(n_components=4), '81': PCA(n_components=3), '82': PCA(n_components=1), '83': PCA(n_components=2), '84': PCA(n_components=2), '85': PCA(n_components=5), '86': PCA(n_components=5), '87': PCA(n_components=4), '88': PCA(n_components=4), '89': PCA(n_components=2), '90': PCA(n_components=2), '91': PCA(n_components=4), '92': PCA(n_components=1), '93': PCA(n_components=5), '94': PCA(n_components=3), '95': PCA(n_components=1), '96': PCA(n_components=3), '97': PCA(n_components=3), '98': PCA(n_components=2), '99': PCA(n_components=1), '100': PCA(n_components=6), '101': PCA(n_components=5), '102': PCA(n_components=4), '103': PCA(n_components=3), '104': PCA(n_components=4), '105': PCA(n_components=4), '106': PCA(n_components=6), '107': PCA(n_components=4), '108': PCA(n_components=3), '109': PCA(n_components=5), '110': PCA(n_components=5), '111': PCA(n_components=5), '112': PCA(n_components=6), '113': PCA(n_components=5), '114': PCA(n_components=5)}\n",
      "predictors_group {'67': AdaBoostRegressor(), '68': AdaBoostRegressor(), '69': AdaBoostRegressor(), '70': AdaBoostRegressor(), '71': AdaBoostRegressor(), '72': AdaBoostRegressor(), '73': AdaBoostRegressor(), '74': AdaBoostRegressor(), '75': AdaBoostRegressor(), '76': AdaBoostRegressor(), '77': AdaBoostRegressor(), '78': AdaBoostRegressor(), '79': AdaBoostRegressor(), '80': AdaBoostRegressor(), '81': AdaBoostRegressor(), '82': AdaBoostRegressor(), '83': AdaBoostRegressor(), '84': AdaBoostRegressor(), '85': AdaBoostRegressor(), '86': AdaBoostRegressor(), '87': AdaBoostRegressor(), '88': AdaBoostRegressor(), '89': AdaBoostRegressor(), '90': AdaBoostRegressor(), '91': AdaBoostRegressor(), '92': AdaBoostRegressor(), '93': AdaBoostRegressor(), '94': AdaBoostRegressor(), '95': AdaBoostRegressor(), '96': AdaBoostRegressor(), '97': AdaBoostRegressor(), '98': AdaBoostRegressor(), '99': AdaBoostRegressor(), '100': AdaBoostRegressor(), '101': AdaBoostRegressor(), '102': AdaBoostRegressor(), '103': AdaBoostRegressor(), '104': AdaBoostRegressor(), '105': AdaBoostRegressor(), '106': AdaBoostRegressor(), '107': AdaBoostRegressor(), '108': AdaBoostRegressor(), '109': AdaBoostRegressor(), '110': AdaBoostRegressor(), '111': AdaBoostRegressor(), '112': AdaBoostRegressor(), '113': AdaBoostRegressor(), '114': AdaBoostRegressor()}\n"
     ]
    }
   ],
   "source": [
    "selector_group = selectors_groups[\"distance_pca_ada_boost_regressor\"]\n",
    "print(\"selector_group\", selector_group)\n",
    "for blendshape_i, selector in selector_group.items():\n",
    "    with open(f\"fm2bs_selector_{blendshape_i}.pkl\", \"wb\") as f:\n",
    "        dump(selector, f)\n",
    "predictors_group = predictors_groups[\"distance_pca_ada_boost_regressor\"]\n",
    "print(\"predictors_group\", predictors_group)\n",
    "for blendshape_i, model in predictors_group.items():\n",
    "    with open(f\"fm2bs_model_{blendshape_i}.pkl\", \"wb\") as f:\n",
    "        dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
