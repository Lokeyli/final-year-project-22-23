{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaeedeaa",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9f6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from sys import __stdout__\n",
    "from ast import literal_eval\n",
    "from pickle import dump\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, MultiTaskLasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from typing import Dict, Set, Tuple, List, Any, Optional, Callable\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression, VarianceThreshold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.pipeline import Pipeline as skPipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_drawing = mp.solutions.drawing_utils # type: ignore\n",
    "mp_drawing_styles = mp.solutions.drawing_styles # type: ignore\n",
    "mp_face_mesh = mp.solutions.face_mesh # type: ignore\n",
    "mp_face_mesh_connections = mp.solutions.face_mesh_connections # type: ignore\n",
    "\n",
    "from settings import *\n",
    "from auxiliary import plot_selected_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e61b626",
   "metadata": {},
   "source": [
    "## Prepare the Training Data\n",
    "\n",
    "See [./landmarkgenerator.py](./landmarkgenerator.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4898d77b",
   "metadata": {},
   "source": [
    "## Define Data Structures and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ab279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendshapeData:\n",
    "    def __init__(self, train_X, test_X, train_Y, test_Y) -> None:\n",
    "        self.train_X = train_X\n",
    "        self.test_X = test_X\n",
    "        self.train_Y = train_Y\n",
    "        self.test_Y = test_Y\n",
    "\n",
    "class BlendshapeTrainingSet:\n",
    "    def __init__(self, blendshape_idx, blendshape_name, X, Y):\n",
    "        self.blendshape_idx = blendshape_idx\n",
    "        self.blendshape_name = blendshape_name\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"BlendshapeData({self.blendshape_idx})\"\n",
    "        \n",
    "blendshape_training_set_lst: List[BlendshapeTrainingSet] = []\n",
    "\n",
    "\n",
    "class DataTransformer:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def transform_X(self, X: DataFrame) -> DataFrame:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Pipeline:\n",
    "\n",
    "    def __init__(self, pipeline_name: str, \n",
    "                dataset_transformer: DataTransformer, \n",
    "                model: Callable,\n",
    "                split: Callable,\n",
    "                selection_method: Optional[Callable] = None,\n",
    "                test_size: float = 0.2,\n",
    "                random_state: int = 42,\n",
    "                shuffle: bool = True) -> None:\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.dataset_transformer: DataTransformer = dataset_transformer\n",
    "        self.selection_method = selection_method\n",
    "        self.model = model\n",
    "        self.split = split\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    # def fit(self, train_df: DataFrame):\n",
    "    #     selectors = dict()\n",
    "    #     predictors = dict()\n",
    "    #     results = []\n",
    "    #     transformed_df = self.dataset_transformer(train_df)\n",
    "    #     global blendshape_idx_lst\n",
    "    #     for blendshape_i in blendshape_idx_lst:\n",
    "    #         sub_df = transformed_df[transformed_df[\"blendshape_i\"] == blendshape_i]\n",
    "    #         reduced_X = sub_df.iloc[:, 2:]\n",
    "    #         Y = sub_df.filter(regex=\"weight\").to_numpy().flatten()\n",
    "    #         selectors[f\"{blendshape_i}\"] = None\n",
    "    #         if self.selection_method:\n",
    "    #             predictor = self.selection_method(reduced_X, Y)\n",
    "    #             reduced_X = predictor.fit_transform(reduced_X, Y)\n",
    "    #             selectors[f\"{blendshape_i}\"] = copy.deepcopy(predictor)\n",
    "    #         splitted_data = self.split(reduced_X, Y)\n",
    "    #         self.model.fit(splitted_data.train_X, splitted_data.train_Y)\n",
    "    #         score = self.model.score(splitted_data.test_X, splitted_data.test_Y)\n",
    "    #         results.append(score)\n",
    "    #         predictors[f\"{blendshape_i}\"] = copy.deepcopy(self.model)\n",
    "    #         # print(f\"{self.pipeline_name}: blendshape_i={blendshape_i}, score={score}\")\n",
    "    #     print(f\"{self.pipeline_name}: mean={np.mean(results)}, min={np.min(results)}, max={np.max(results)}\")\n",
    "    #     return selectors, predictors\n",
    "    \n",
    "    def fit_(self, training_set_list: List[BlendshapeTrainingSet], verbose: int = 1):\n",
    "        selectors = dict()\n",
    "        predictors = dict()\n",
    "        results = []\n",
    "        for training_set in training_set_list:\n",
    "            new_X = self.dataset_transformer.transform_X(training_set.X)\n",
    "            if self.selection_method:\n",
    "                predictor = self.selection_method(new_X, training_set.Y)\n",
    "                new_X = predictor.fit_transform(new_X, training_set.Y)\n",
    "                print(predictor.get_support())\n",
    "                selectors[f\"{training_set.blendshape_idx}\"] = copy.deepcopy(predictor)\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                new_X, training_set.Y, test_size=self.test_size, \n",
    "                random_state=self.random_state, shuffle=self.shuffle)\n",
    "            self.model.fit(X_train, Y_train)\n",
    "            score = self.model.score(X_test, Y_test)\n",
    "            results.append(score)\n",
    "            predictors[f\"{training_set.blendshape_idx}\"] = copy.deepcopy(self.model)\n",
    "            break\n",
    "        if verbose > 0:\n",
    "            print(f\"{self.pipeline_name}: mean={np.mean(results)}, min={np.min(results)}, max={np.max(results)}\")\n",
    "        return selectors, predictors    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d8f8538",
   "metadata": {},
   "source": [
    "## Helper Functions for Debugging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc92ad16",
   "metadata": {},
   "source": [
    "### Plot the selected features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c1e4605",
   "metadata": {},
   "source": [
    "See [./auxiliary.py:plot_selected_features](./auxiliary.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afdd7c5d",
   "metadata": {},
   "source": [
    "## Load Train Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea8c052a",
   "metadata": {},
   "source": [
    "### For Multi-task Regression\n",
    "\n",
    "For Multi-task Regression use. All the data from the dataset CSV are load into a single dataframe, such that\n",
    "\n",
    "$ x_{i,j} \\in X, i \\leq n, j \\leq m $ where $X$ is a $n * m$ matrix, is the $j^{th}$ landmark of the $i^{th}$ training data element.\n",
    "\n",
    "$ y_i \\in Y, i \\leq n$ where $Y$ is a $n * 1$ matrix, is the list of blendshape of that element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12118f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(TRAIN_FILE, header=0, delimiter=\",\", index_col=False)\n",
    "multitask_Y : DataFrame = tmp_df[\"weight\"].to_frame()\n",
    "multitask_Y = multitask_Y.applymap(literal_eval).applymap(np.array)\n",
    "## Assuming 1st column blendshape index and 2nd column is the weight list.\n",
    "multitask_X : DataFrame = tmp_df.iloc[:, 2:]\n",
    "multitask_X = multitask_X.applymap(literal_eval).applymap(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e09f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19392, 478)\n",
      "(19392, 1)\n"
     ]
    }
   ],
   "source": [
    "print(multitask_X.shape)\n",
    "print(multitask_Y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6296e412",
   "metadata": {},
   "source": [
    "### For multi models regression\n",
    "\n",
    "All the data from the dataset CSV are load into a list of dataframes, such that\n",
    "\n",
    "$ dataframe_i$ in list is a dataframe for a specific blendshape.\n",
    "\n",
    "$ x_{i,j} \\in X, i \\leq n, j \\leq m $ where $X$ is a $n * m$ matrix, is the $j^{th}$ landmark of the $i^{th}$ training data element of this specific blendshape.\n",
    "\n",
    "$ y_i \\in y, i \\leq n$ where $y$ is a **vector**, is the weight of that blendshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "615c0f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 34\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mfor\u001b[39;00m blendshape_idx \u001b[39min\u001b[39;00m blendshape_idx_lst:\n\u001b[1;32m     25\u001b[0m         blendshape_training_set_lst\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     26\u001b[0m             BlendshapeTrainingSet(\n\u001b[1;32m     27\u001b[0m                 blendshape_idx\u001b[39m=\u001b[39mblendshape_idx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m             )\n\u001b[1;32m     33\u001b[0m         )\n\u001b[0;32m---> 34\u001b[0m load_data()\n",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m blendshape_idx_lst \u001b[39m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m     15\u001b[0m     TRAIN_FILE, header\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m name_val \u001b[39m=\u001b[39m [name_df\u001b[39m.\u001b[39mloc[name_df[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m idx]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m train_df[\u001b[39m\"\u001b[39m\u001b[39mblendshape_i\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     18\u001b[0m train_df\u001b[39m.\u001b[39minsert(\u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mblendshape_name\u001b[39m\u001b[39m\"\u001b[39m, name_val)\n\u001b[1;32m     19\u001b[0m blendshape_idx_lst \u001b[39m=\u001b[39m train_df[\u001b[39m\"\u001b[39m\u001b[39mblendshape_i\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdrop_duplicates()\u001b[39m.\u001b[39mto_list()\n",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m blendshape_idx_lst \u001b[39m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m     15\u001b[0m     TRAIN_FILE, header\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m name_val \u001b[39m=\u001b[39m [name_df\u001b[39m.\u001b[39mloc[name_df[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m idx]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m train_df[\u001b[39m\"\u001b[39m\u001b[39mblendshape_i\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     18\u001b[0m train_df\u001b[39m.\u001b[39minsert(\u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mblendshape_name\u001b[39m\u001b[39m\"\u001b[39m, name_val)\n\u001b[1;32m     19\u001b[0m blendshape_idx_lst \u001b[39m=\u001b[39m train_df[\u001b[39m\"\u001b[39m\u001b[39mblendshape_i\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdrop_duplicates()\u001b[39m.\u001b[39mto_list()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_df' is not defined"
     ]
    }
   ],
   "source": [
    "## %%script echo skip\n",
    "\n",
    "blendshape_training_set_lst = []\n",
    "\n",
    "def str_splitted_by_space_to_list(s: str) -> list:\n",
    "    return [float(x) for x in s.strip(\"[\").strip(\"]\").split()]\n",
    "\n",
    "all_X = None\n",
    "OVERALL_Y = None\n",
    "\n",
    "def load_data() -> None:\n",
    "    # name_df = pd.read_csv(\"blendshapes_name.csv\", header=0, delimiter=\",\", index_col=False)\n",
    "    blendshape_idx_lst = []\n",
    "    train_df = pd.read_csv(\n",
    "        TRAIN_FILE, header=0, delimiter=\",\", index_col=False\n",
    "    )\n",
    "    # name_val = [name_df.loc[name_df[\"index\"] == idx].iloc[0, 1].strip() for idx in train_df[\"blendshape_i\"]]\n",
    "    # train_df.insert(1, \"blendshape_name\", name_val)\n",
    "    blendshape_idx_lst = train_df[\"blendshape_i\"].drop_duplicates().to_list()\n",
    "    landmarks = train_df.columns[3:].to_list()\n",
    "    train_df[landmarks] = train_df[landmarks].applymap(literal_eval).applymap(np.array)\n",
    "    global all_X\n",
    "    all_X = train_df[landmarks]\n",
    "    for blendshape_idx in blendshape_idx_lst:\n",
    "        blendshape_training_set_lst.append(\n",
    "            BlendshapeTrainingSet(\n",
    "                blendshape_idx=blendshape_idx,\n",
    "                # blendshape_name=train_df[train_df[\"blendshape_i\"] == blendshape_idx][\"blendshape_name\"],\n",
    "                blendshape_name = \"\",\n",
    "                X=train_df[train_df[\"blendshape_i\"] == blendshape_idx][landmarks],\n",
    "                Y=train_df[train_df[\"blendshape_i\"] == blendshape_idx][\"weight\"],\n",
    "            )\n",
    "        )\n",
    "load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, Y = make_regression(n_samples=10, n_features=30, n_targets=3, random_state=42)\n",
    "\n",
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775cb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blendshape_training_set_lst[0].blendshape_idx, blendshape_training_set_lst[0].blendshape_name)\n",
    "print( blendshape_training_set_lst[0].Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b2bb745",
   "metadata": {},
   "source": [
    "## Transforming Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ead703dd",
   "metadata": {},
   "source": [
    "### Default training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a46625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultFeatures(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Produce the training set that using 478 landmarks' coordinates (1434 in total) as features\n",
    "\n",
    "        Args:\n",
    "            input_df (DataFrame): the origin dataframe from csv file\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: the training set with distance between landmarks\n",
    "        \"\"\"\n",
    "        default_train_columns = (X.columns.to_list()\n",
    "            + [f\"{i}_landmark_{j}\" for i in range(N_LANDMARKS) for j in [\"x\", \"y\", \"z\"]])\n",
    "\n",
    "        default_X =[]\n",
    "\n",
    "        for _, row in X.iterrows():\n",
    "            default_X.append(np.concatenate(row.values))\n",
    "        default_X = DataFrame(data=default_X, columns=default_train_columns)\n",
    "        return default_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5911c74",
   "metadata": {},
   "source": [
    "### Distance training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0383d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Produce the training set with distance between certain sets of landmarks\n",
    "\n",
    "        Args:\n",
    "            input_df (DataFrame): the origin dataframe from csv file\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: the training set with distance between landmarks\n",
    "        \"\"\"\n",
    "        vertices_sets: Dict[str, Set[Tuple[int, int]]] = {\n",
    "            \"FACEMESH_FACE_OVAL\": mp_face_mesh_connections.FACEMESH_FACE_OVAL,\n",
    "            \"FACEMESH_LIPS\": mp_face_mesh_connections.FACEMESH_LIPS, \n",
    "            \"FACEMESH_LEFT_EYE\": mp_face_mesh_connections.FACEMESH_LEFT_EYE,\n",
    "            \"FACEMESH_LEFT_IRIS\": mp_face_mesh_connections.FACEMESH_LEFT_IRIS,\n",
    "            \"FACEMESH_LEFT_EYEBROW\": mp_face_mesh_connections.FACEMESH_LEFT_EYEBROW,\n",
    "            \"FACEMESH_RIGHT_EYE\": mp_face_mesh_connections.FACEMESH_RIGHT_EYE,\n",
    "            \"FACEMESH_RIGHT_EYEBROW\": mp_face_mesh_connections.FACEMESH_RIGHT_EYEBROW,\n",
    "            \"FACEMESH_RIGHT_IRIS\": mp_face_mesh_connections.FACEMESH_RIGHT_IRIS}\n",
    "        vertices_sets_new_val = map(tuple_set_to_list, vertices_sets.values())\n",
    "        vertices_sets = dict(zip(vertices_sets.keys(), vertices_sets_new_val))\n",
    "\n",
    "        NOSE_IDX = 1\n",
    "        TOP_DOWN_FACE = (10,152)\n",
    "        LEFT_RIGHT_OUTER_EYE = (263, 33)\n",
    "        LEFT_RIGHT_MOUSE= (61, 291)\n",
    "\n",
    "        # define the column names\n",
    "        new_columns = list()\n",
    "        for name, vertices_set in vertices_sets.items():\n",
    "            for _, vertices in enumerate(vertices_set):\n",
    "                column = f\"{name}_distance_{vertices}\"\n",
    "                new_columns.append(column)\n",
    "\n",
    "        distance_X = DataFrame(columns=new_columns, dtype=np.float64)\n",
    "\n",
    "        for i, row in X.iterrows():\n",
    "            new_row = list()\n",
    "            middle_point_x = np.mean([(row[LEFT_RIGHT_OUTER_EYE[0]][0] + row[LEFT_RIGHT_OUTER_EYE[1]][0]) / 2, \n",
    "                (row[LEFT_RIGHT_MOUSE[0]][0] + row[LEFT_RIGHT_MOUSE[1]][0]) / 2, row[NOSE_IDX][0]])\n",
    "            middle_point_y = ((row[TOP_DOWN_FACE[0]] + row[TOP_DOWN_FACE[1]]) / 2)[1]\n",
    "            middle_point_z = 0\n",
    "            middle_point = [middle_point_x, middle_point_y, middle_point_z]\n",
    "            normalised_distance = np.linalg.norm(row[TOP_DOWN_FACE[0]] - row[TOP_DOWN_FACE[1]])\n",
    "            for name, vertices_set in vertices_sets.items():\n",
    "                for _, vertex in enumerate(vertices_set):\n",
    "                    distance = np.linalg.norm(row[vertex] - middle_point)\n",
    "                    new_row.append(distance)\n",
    "            distance_X.loc[i] = [distance / normalised_distance for distance in new_row] # type: ignore\n",
    "        ## distance_X.to_csv(\"test_dis.csv\", index=False)  \n",
    "        return distance_X\n",
    "\n",
    "    def _tuple_set_to_list(in_set: Set[Tuple]) -> List:\n",
    "        return list({element for tuple_ in in_set for element in tuple_})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8f50a4f",
   "metadata": {},
   "source": [
    "### Full Distance Training Set\n",
    "\n",
    "The training set base on distances that includes all the points, labelled by their index in MediaPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7239dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDistance(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Produce the training set with distance between certain sets of landmarks\n",
    "\n",
    "        Args:\n",
    "            input_df (DataFrame): the origin dataframe from csv file\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: the training set with distance between landmarks\n",
    "        \"\"\"\n",
    "\n",
    "        NOSE_IDX = 1\n",
    "        TOP_DOWN_FACE = (10,152)\n",
    "\n",
    "        # define the column names\n",
    "        new_columns = list()\n",
    "        for idx, _ in enumerate(X.columns):\n",
    "            new_columns.append(f\"distance_{idx}\")\n",
    "\n",
    "        distance_X = DataFrame(columns=new_columns, dtype=np.float64)\n",
    "\n",
    "        for i, row in X.iterrows():\n",
    "            new_row = list()\n",
    "            middle_point = row[NOSE_IDX][:]\n",
    "            middle_point[1] = (row[TOP_DOWN_FACE[0]][1] + row[TOP_DOWN_FACE[1]][1]) / 2\n",
    "            max_distance = row[TOP_DOWN_FACE[0]] - row[TOP_DOWN_FACE[1]]\n",
    "            normalised_distance = np.linalg.norm(max_distance)\n",
    "            for _, landmark in enumerate(row):\n",
    "                distance = np.linalg.norm(landmark - middle_point)\n",
    "                new_row.append(distance)\n",
    "            ## distance_X.loc[i] = [distance / normalised_distance for distance in new_row] # type: ignore\n",
    "            distance_X.loc[i] = [distance for distance in new_row] # type: ignore\n",
    "        return distance_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47885b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaneCoordinate(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Produce the training set with the x, y coordinates of landmarks.\n",
    "\n",
    "        The generated coordinates are \n",
    "        Args:\n",
    "            input_df (DataFrame): the origin dataframe from csv file\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: the training set with distance between landmarks\n",
    "        \"\"\"\n",
    "\n",
    "        NOSE_IDX = 1\n",
    "        TOP_DOWN_FACE = (10,152)\n",
    "        LEFT_RIGHT_OUTER_EYE = (263, 33)\n",
    "        LEFT_RIGHT_MOUSE= (61, 291)\n",
    "\n",
    "        # define the column names\n",
    "        new_columns = list()\n",
    "        for idx, _ in enumerate(X.columns):\n",
    "            new_columns.append(f\"distance_{idx}\")\n",
    "\n",
    "        distance_X = DataFrame(columns=new_columns, dtype=np.float64)\n",
    "\n",
    "        for i, row in X.iterrows():\n",
    "            new_row = list()\n",
    "            middle_point_x = np.mean([(row[LEFT_RIGHT_OUTER_EYE[0]][0] + row[LEFT_RIGHT_OUTER_EYE[1]][0]) / 2, \n",
    "                (row[LEFT_RIGHT_MOUSE[0]][0] + row[LEFT_RIGHT_MOUSE[1]][0]) / 2, row[NOSE_IDX][0]])\n",
    "            middle_point_y = ((row[TOP_DOWN_FACE[0]] + row[TOP_DOWN_FACE[1]]) / 2)[1]\n",
    "            middle_point_z = 0\n",
    "            middle_point = [middle_point_x, middle_point_y, middle_point_z]\n",
    "            normalised_distance = np.linalg.norm(row[TOP_DOWN_FACE[0]] - row[TOP_DOWN_FACE[1]])\n",
    "            \n",
    "            for _, landmark in enumerate(row):\n",
    "                distance = np.linalg.norm(landmark - middle_point)\n",
    "                new_row.append(distance)\n",
    "            distance_X.loc[i] = [distance / normalised_distance for distance in new_row] # type: ignore\n",
    "        return distance_X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab64aa5f",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into Train, Test and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_split(X, Y) -> BlendshapeData:\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(\n",
    "            X, Y, test_size=0.2, random_state=42, shuffle=True\n",
    "        )\n",
    "    return BlendshapeData(train_X, test_X, train_Y, test_Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d67a54db",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_methods: Dict[str, Callable] = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "861f1e79",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_pca(X, Y) -> PCA:\n",
    "    n: int = min(X.shape)\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X=X, y=Y)\n",
    "    explained_variance_ratios = pca.explained_variance_ratio_ # type: ignore\n",
    "    for i in range(n):\n",
    "        if sum(explained_variance_ratios[:i]) > 0.95:\n",
    "            n = i\n",
    "            break\n",
    "    pca = PCA(n_components=n)\n",
    "    return pca\n",
    "    \n",
    "selection_methods[\"PCA\"] = selection_pca\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cfdfae4",
   "metadata": {},
   "source": [
    "### Selected K Best base on Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcdb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_k_best_chi2(X, Y) -> SelectKBest:\n",
    "    # k = 0\n",
    "    # selector = SelectKBest(chi2, k=10)\n",
    "    # selector.fit(X, Y)\n",
    "    # selected_features = selector.get_support(indices=True)\n",
    "    # selected_features = sorted(selected_features, key = lambda x: selector.scores_[x], reverse=True)\n",
    "    # for i in range(len(selected_features)):\n",
    "    #     if selector.scores_[selected_features[i]] > 0.010:\n",
    "    #         k += 1\n",
    "    #     else:\n",
    "    #         break\n",
    "    selector = SelectKBest(chi2, k=7)\n",
    "    return selector\n",
    "\n",
    "selection_methods[\"chi2\"] = selection_k_best_chi2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09e461ff",
   "metadata": {},
   "source": [
    "### Selected K Best base on ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cab2c514",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "models: Dict[str, Callable]  = dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e509969",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "173ffe66",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"linear-regression\"] = LinearRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df481a3f",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"logistic-regression\"] = LogisticRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33434706",
   "metadata": {},
   "source": [
    "### Ensemble Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "506fc098",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"random_forest_regressor\"] = RandomForestRegressor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "415b88df",
   "metadata": {},
   "source": [
    "#### Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"ada_boost_regressor\"] = AdaBoostRegressor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe721b5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b0b5f25",
   "metadata": {},
   "source": [
    "### Define the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f82527",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines: Dict[str, Pipeline] = dict()\n",
    "\n",
    "# pipelines[\"default_random_forest_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"default_random_forest_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"default\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"random_forest_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_random_forest_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_random_forest_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"random_forest_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"default_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"default_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"default\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=None,\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"default_pca_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"default_pca_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"default\"],\n",
    "#     selection_method=selection_methods[\"PCA\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_pca_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_pca_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"PCA\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "\n",
    "## Chi2 only allow non-negative values,\n",
    "## therefore, the default set is not applicable\n",
    "\n",
    "# pipelines[\"distance_chi2_linear_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_chi2_linear_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"chi2\"],\n",
    "#     model=models[\"linear-regression\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_chi2_random_forest_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_chi2_random_forest_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"chi2\"],\n",
    "#     model=models[\"random_forest_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_chi2_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_chi2_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"chi2\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "pipelines[\"full_distance_chi2_linear_regressor\"] = Pipeline(\n",
    "    pipeline_name=\"full_distance_chi2_linear_regressor\",\n",
    "    dataset_transformer=training_set_transformers[\"full_distance\"],\n",
    "    selection_method=selection_methods[\"chi2\"],\n",
    "    model=models[\"linear-regression\"],\n",
    "    split=default_split)\n",
    "pipelines[\"full_distance_chi2_random_forest_regressor\"] = Pipeline(\n",
    "    pipeline_name=\"full_distance_chi2_random_forest_regressor\",\n",
    "    dataset_transformer=training_set_transformers[\"full_distance\"],\n",
    "    selection_method=selection_methods[\"chi2\"],\n",
    "    model=models[\"random_forest_regressor\"],\n",
    "    split=default_split)\n",
    "pipelines[\"full_distance_chi2_ada_boost_regressor\"] = Pipeline(\n",
    "    pipeline_name=\"full_distance_chi2_ada_boost_regressor\",\n",
    "    dataset_transformer=training_set_transformers[\"full_distance\"],\n",
    "    selection_method=selection_methods[\"chi2\"],\n",
    "    model=models[\"ada_boost_regressor\"],\n",
    "    split=default_split)\n",
    "# pipelines[\"distance_tsne_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_tsne_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"TSNE\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)\n",
    "# pipelines[\"distance_tsne_ada_boost_regressor\"] = Pipeline(\n",
    "#     pipeline_name=\"distance_tsne_ada_boost_regressor\",\n",
    "#     dataset_transformer=training_set_transformers[\"distance\"],\n",
    "#     selection_method=selection_methods[\"TSNE\"],\n",
    "#     model=models[\"ada_boost_regressor\"],\n",
    "#     split=default_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pipelines = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60236485",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blendshape_training_set_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(blendshape_training_set_lst))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blendshape_training_set_lst' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(blendshape_training_set_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea89c722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 83\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# searches.append(GridSearchCV(\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m#                 estimator=fulldistance_chi2_gridsearch_linear_regressor, \u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m#                 param_grid={\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m#                 cv=2)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m#                 )\u001b[39;00m\n\u001b[1;32m     73\u001b[0m searches\u001b[39m.\u001b[39mappend(GridSearchCV(\n\u001b[1;32m     74\u001b[0m estimator\u001b[39m=\u001b[39mfulldistance_multilasso,\n\u001b[1;32m     75\u001b[0m param_grid\u001b[39m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m cv\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     82\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m searches[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mfit(multitask_X, multitask_Y)\n\u001b[1;32m     84\u001b[0m \u001b[39m# searches.append(GridSearchCV(\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m#                 estimator=fulldistance_varthershold_gridsearch_svr,\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m#                 param_grid=[{\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m# train_on_each_blendshape()\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m# train_on_all_data()\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1388\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/pipeline.py:402\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \n\u001b[1;32m    378\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 402\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    403\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    404\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/pipeline.py:360\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    358\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    359\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    361\u001b[0m     cloned_transformer,\n\u001b[1;32m    362\u001b[0m     X,\n\u001b[1;32m    363\u001b[0m     y,\n\u001b[1;32m    364\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    365\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    366\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    367\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    368\u001b[0m )\n\u001b[1;32m    369\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/pipeline.py:894\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    893\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 894\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    895\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/base.py:851\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 851\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m, in \u001b[0;36mFullDistance.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m         distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(landmark \u001b[39m-\u001b[39m middle_point)\n\u001b[1;32m     42\u001b[0m         new_row\u001b[39m.\u001b[39mappend(distance)\n\u001b[0;32m---> 43\u001b[0m     distance_X\u001b[39m.\u001b[39;49mloc[i] \u001b[39m=\u001b[39m [distance \u001b[39m/\u001b[39m normalised_distance \u001b[39mfor\u001b[39;00m distance \u001b[39min\u001b[39;00m new_row] \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m distance_X\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/indexing.py:1785\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1782\u001b[0m     indexer, missing \u001b[39m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[0;32m-> 1785\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_missing(indexer, value)\n\u001b[1;32m   1786\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mloc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1789\u001b[0m     \u001b[39m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/indexing.py:2182\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m   2181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_append(value)\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m   2183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_maybe_update_cacher(clear\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/frame.py:9805\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   9802\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   9803\u001b[0m     to_concat \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m, other]\n\u001b[0;32m-> 9805\u001b[0m result \u001b[39m=\u001b[39m concat(\n\u001b[1;32m   9806\u001b[0m     to_concat,\n\u001b[1;32m   9807\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m   9808\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m   9809\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9810\u001b[0m )\n\u001b[1;32m   9811\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/pandas/core/internals/concat.py:223\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    217\u001b[0m vals \u001b[39m=\u001b[39m [ju\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m ju \u001b[39min\u001b[39;00m join_units]\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m blk\u001b[39m.\u001b[39mis_extension:\n\u001b[1;32m    220\u001b[0m     \u001b[39m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[39m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[39m#  than concat_compat\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(vals, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     values \u001b[39m=\u001b[39m concat_compat(vals, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CustomVarianceThreshold(VarianceThreshold):\n",
    "\n",
    "    def __init__(self, threshold=0.0, step=1.0e-7, max_iteration=1000):\n",
    "        super().__init__(threshold=threshold)\n",
    "        self.try_count = 0\n",
    "        self.step = step\n",
    "        self.max_iteration = max_iteration\n",
    "    \n",
    "    def fit_transform(self, X, y = None, **fit_params):\n",
    "        try:\n",
    "            return super().fit_transform(X, y, **fit_params)\n",
    "        except ValueError:\n",
    "            while True:\n",
    "                self.threshold -= self.threshold\n",
    "                if self.try_count > self.max_iteration:\n",
    "                    self.threshold=0\n",
    "                    print(\"No suitable threshold, new threshold = 0\")\n",
    "                    return super().fit_transform(X, y, **fit_params)\n",
    "                self.max_iteration += 1\n",
    "                try:\n",
    "                    return super().fit_transform(X, y, **fit_params)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "weight = 100\n",
    "searches = []\n",
    "fulldistance_chi2_gridsearch_linear_regressor = skPipeline(steps=[('data_transform', FullDistance()), ('feature_selection', SelectKBest(chi2)), ('regression', LinearRegression())])\n",
    "# param_grid =  {\n",
    "#     'data_transform__k': [k for k in range(1,10)]\n",
    "# }\n",
    "\n",
    "fulldistance_infogain_gridsearch_linear_regressor = skPipeline(steps=[('data_transform', FullDistance()), ('feature_selection', SelectKBest(mutual_info_regression)), ('regression', LinearRegression())])\n",
    "# param_grid =  {\n",
    "#     'data_transform__k': [k for k in range(1,10)]\n",
    "# }\n",
    "\n",
    "fulldistance_varthershold_gridsearch_linear_regressor = skPipeline(steps=[('data_transform', FullDistance()), ('feature_selection', CustomVarianceThreshold()), ('regression', LinearRegression())])\n",
    "\n",
    "fulldistance_varthershold_gridsearch_svr = skPipeline(steps=[('data_transform', FullDistance()), ('feature_selection', CustomVarianceThreshold()), ('regression', SVR())])\n",
    "\n",
    "fulldistance_multilasso = skPipeline(steps=[('data_transform', FullDistance()), ('regression', MultiTaskLasso())])\n",
    "\n",
    "def custom_score_func(pipeline, X, y):\n",
    "\n",
    "    feature_selector = pipeline.named_steps['chi2']\n",
    "    _landmarks = feature_selector.get_support(indices=True)\n",
    "    \n",
    "\n",
    "# searches.append(GridSearchCV(\n",
    "#                 estimator=fulldistance_chi2_gridsearch_linear_regressor, \n",
    "#                 param_grid={\n",
    "#                     'feature_selection__k': [k for k in range(1,10)]\n",
    "#                 }, \n",
    "#                 return_train_score=True, \n",
    "#                 error_score='raise'))\n",
    "# searches.append(GridSearchCV(\n",
    "#                 estimator=fulldistance_infogain_gridsearch_linear_regressor, \n",
    "#                 param_grid={\n",
    "#                     'feature_selection__k': [k for k in range(1,10)]\n",
    "#                 }, \n",
    "#                 return_train_score=True, \n",
    "#                 error_score='raise'))\n",
    "# searches.append(GridSearchCV(\n",
    "#                 estimator=fulldistance_varthershold_gridsearch_linear_regressor,\n",
    "#                 param_grid={\n",
    "#                     'feature_selection__threshold': [2.5e-5]\n",
    "#                 }, \n",
    "#                 return_train_score=True, \n",
    "#                 error_score='raise',\n",
    "#                 verbose=3,\n",
    "#                 cv=2)\n",
    "#                 )\n",
    "searches.append(GridSearchCV(\n",
    "estimator=fulldistance_multilasso,\n",
    "param_grid={\n",
    "    'regression__alpha': [1.0, 1.5]\n",
    "}, \n",
    "return_train_score=True, \n",
    "error_score='raise',\n",
    "verbose=3,\n",
    "cv=2)\n",
    ")\n",
    "searches[0].fit(multitask_X, multitask_Y)\n",
    "# searches.append(GridSearchCV(\n",
    "#                 estimator=fulldistance_varthershold_gridsearch_svr,\n",
    "#                 param_grid=[{\n",
    "#                     'feature_selection__threshold': [2.5e-5],\n",
    "#                     'regression__C': [0.75, 1, 1,5],\n",
    "#                     'regression__kernel': ['linear'],\n",
    "#                     'regression__epsilon': [0.5, 1, 2],\n",
    "#                 },\n",
    "#                 {\n",
    "#                     'feature_selection__threshold': [2.5e-5],\n",
    "#                     'regression__C': [0.75, 1, 1,5],\n",
    "#                     'regression__kernel': ['rbf'],\n",
    "#                     'regression__epsilon': [0.5, 1, 2],\n",
    "#                     'regression__gamma': ['auto', 'scale'],\n",
    "#                 }], \n",
    "#                 return_train_score=True, \n",
    "#                 error_score='raise',\n",
    "#                 verbose=3,\n",
    "#                 cv=2)\n",
    "#                 )\n",
    "\n",
    "# def train_on_each_blendshape():\n",
    "#     for search in searches:\n",
    "#         tmp_res = []\n",
    "#         for training_set in blendshape_training_set_lst[:]: \n",
    "#             print(training_set.blendshape_idx)\n",
    "#             print(training_set.blendshape_name.to_list()[0])\n",
    "#             search.fit(training_set.X, training_set.Y)\n",
    "#             print(\"Best Estimator:\", search.best_estimator_)\n",
    "#             print(\"Best Train Score:\", search.best_score_)\n",
    "#             tmp_res.append(search.best_estimator_)\n",
    "#             best_filter = search.best_estimator_.named_steps[\"feature_selection\"]\n",
    "#             best_landmarks = best_filter.get_support(indices=True)\n",
    "#             filename_idx = training_set.blendshape_idx\n",
    "#             filename_data_transform = search.best_estimator_.named_steps['data_transform'].__class__.__name__\n",
    "#             filename_feature_selection = search.best_estimator_.named_steps['feature_selection'].__class__.__name__\n",
    "#             if search.best_estimator_.named_steps['feature_selection'].__class__ == SelectKBest:\n",
    "#                 filename_feature_selection += f\"{search.best_estimator_.named_steps['feature_selection'].score_func.__name__}\"\n",
    "#             filename_regression_model = search.best_estimator_.named_steps['regression'].__class__.__name__\n",
    "#             plot_selected_features(f\"./index{training_set.blendshape_idx}-weight${weight}.png\", best_landmarks, f\"{filename_idx}_{filename_data_transform}_{filename_feature_selection}_{filename_regression_model}\")\n",
    "#         result_pipelines[f\"{filename_data_transform}_{filename_feature_selection}_{filename_regression_model}\"] = tmp_res\n",
    "\n",
    "# def train_on_all_data():\n",
    "\n",
    "#     def transform_y(y, idx: int):\n",
    "#         target = y\n",
    "#         target = [0 for blendshape in blendshape_training_set_lst[:idx] for j in range(blendshape.Y.shape[0])]\\\n",
    "#                 + target\\\n",
    "#                 + [0 for blendshape in blendshape_training_set_lst[min(len(blendshape_training_set_lst), idx+1):] for j in range(blendshape.Y.shape[0])]\n",
    "#         return target\n",
    "\n",
    "#     for search in searches:\n",
    "#         tmp_res = []\n",
    "#         for idx, training_set in enumerate(blendshape_training_set_lst[:]): \n",
    "#             print(training_set.blendshape_idx)\n",
    "#             print(training_set.blendshape_name.to_list()[0])\n",
    "#             search.fit(all_X, transform_y(training_set.Y.to_list(), idx))\n",
    "#             print(\"Best Estimator:\", search.best_estimator_)\n",
    "#             print(\"Best Train Score:\", search.best_score_)\n",
    "#             tmp_res.append(search.best_estimator_)\n",
    "#             best_filter = search.best_estimator_.named_steps[\"feature_selection\"]\n",
    "#             best_landmarks = best_filter.get_support(indices=True)\n",
    "#             filename_idx = training_set.blendshape_idx\n",
    "#             filename_data_transform = search.best_estimator_.named_steps['data_transform'].__class__.__name__\n",
    "#             filename_feature_selection = search.best_estimator_.named_steps['feature_selection'].__class__.__name__\n",
    "#             if search.best_estimator_.named_steps['feature_selection'].__class__ == SelectKBest:\n",
    "#                 filename_feature_selection += f\"{search.best_estimator_.named_steps['feature_selection'].score_func.__name__}\"\n",
    "#             filename_regression_model = search.best_estimator_.named_steps['regression'].__class__.__name__\n",
    "#             # plot_selected_features(f\"./index{training_set.blendshape_idx}-weight${weight}.png\", best_landmarks, f\"{filename_idx}_{filename_data_transform}_{filename_feature_selection}_{filename_regression_model}\")\n",
    "#         result_pipelines[f\"all_{filename_data_transform}_{filename_feature_selection}_{filename_regression_model}\"] = tmp_res\n",
    "\n",
    "# train_on_each_blendshape()\n",
    "# train_on_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_10\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 500, 500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# p = skPipeline(steps=[('data_transform', FullDistance()), ('feature_selection', CustomVarianceThreshold()), ('regression', TensorFlowCNN())])\u001b[39;00m\n\u001b[1;32m     39\u001b[0m cnn \u001b[39m=\u001b[39m TensorFlowCNN()\n\u001b[0;32m---> 40\u001b[0m cnn\u001b[39m.\u001b[39;49mbuild_model((\u001b[39m500\u001b[39;49m, \u001b[39m500\u001b[39;49m), \u001b[39m50\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m, in \u001b[0;36mTensorFlowCNN.build_model\u001b[0;34m(self, input_shape, output_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     model_layers \u001b[39m=\u001b[39m [layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)]\n\u001b[0;32m---> 29\u001b[0m     model_layers\u001b[39m.\u001b[39mappend(tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m)(model_layers[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]))\n\u001b[1;32m     30\u001b[0m     \u001b[39m# model_layers.append(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # 2x2最大池化层\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39m# model_layers.append(tf.keras.layers.Conv2D(3, (6, 6), activation='relu'))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     output \u001b[39m=\u001b[39m [layers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_output\u001b[39m\u001b[39m'\u001b[39m)(hidden_layers[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(output_size)]\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/keras/engine/input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 253\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_10\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 500, 500)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models as keras_models\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class TensorFlowCNN(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.model_ = self.build_model(X.shape, len(list(y)))\n",
    "\n",
    "        self.model_.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "        self.model_.fit(X, y, epochs=10, verbose=0)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'model_')\n",
    "        X = check_array(X)\n",
    "        return self.model_.predict(X)\n",
    "\n",
    "    def build_model(self, input_shape, output_size):\n",
    "        if self.model is None:\n",
    "            model_layers = [layers.Input(shape=input_shape)]\n",
    "            model_layers.append(tf.keras.layers.Conv2D(2, 3, activation='relu')(model_layers[-1]))\n",
    "            # model_layers.append(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # 2x2最大池化层\n",
    "            # model_layers.append(tf.keras.layers.Conv2D(3, (6, 6), activation='relu'))\n",
    "            output = [layers.Dense(1, activation='linear', name=f'task{i}_output')(hidden_layers[-1]) for i in range(output_size)]\n",
    "            model = keras_models.Model(inputs=input_, outputs=output)\n",
    "            print(model.summary())\n",
    "            return model\n",
    "        return self.model\n",
    "\n",
    "# p = skPipeline(steps=[('data_transform', FullDistance()), ('feature_selection', CustomVarianceThreshold()), ('regression', TensorFlowCNN())])\n",
    "cnn = TensorFlowCNN()\n",
    "cnn.build_model((500, 500), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f4acf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullDistance_CustomVarianceThreshold_LinearRegression\n"
     ]
    }
   ],
   "source": [
    "for name in result_pipelines.keys():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aee4eb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_pipelines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m idx_to_plot \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m BEGIN_IDX\n\u001b[1;32m      5\u001b[0m SELECTED_PIPELINE \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFullDistance_CustomVarianceThreshold_LinearRegression\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m transformed_X \u001b[39m=\u001b[39m result_pipelines[SELECTED_PIPELINE][idx_to_plot]\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mdata_transform\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtransform(all_X)\n\u001b[1;32m      8\u001b[0m transformed_X \u001b[39m=\u001b[39m result_pipelines[SELECTED_PIPELINE][idx_to_plot]\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mfeature_selection\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtransform(transformed_X)\n\u001b[1;32m      9\u001b[0m target \u001b[39m=\u001b[39m blendshape_training_set_lst[idx_to_plot]\u001b[39m.\u001b[39mY\u001b[39m.\u001b[39mto_list()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_pipelines' is not defined"
     ]
    }
   ],
   "source": [
    "idx_to_plot = 68\n",
    "BEGIN_IDX = 67\n",
    "END_IDX = 114 - BEGIN_IDX\n",
    "idx_to_plot -= BEGIN_IDX\n",
    "SELECTED_PIPELINE = \"FullDistance_CustomVarianceThreshold_LinearRegression\"\n",
    "\n",
    "transformed_X = result_pipelines[SELECTED_PIPELINE][idx_to_plot].named_steps['data_transform'].transform(all_X)\n",
    "transformed_X = result_pipelines[SELECTED_PIPELINE][idx_to_plot].named_steps['feature_selection'].transform(transformed_X)\n",
    "target = blendshape_training_set_lst[idx_to_plot].Y.to_list()\n",
    "new_df = pd.DataFrame(transformed_X, columns=[f\"feature_{i}\" for i in range(len(transformed_X[0]))])\n",
    "target = [0 for blendshape in blendshape_training_set_lst[:idx_to_plot] for j in range(blendshape.Y.shape[0])]\\\n",
    "            + target\\\n",
    "            + [0 for blendshape in blendshape_training_set_lst[min(END_IDX, idx_to_plot+1):] for j in range(blendshape.Y.shape[0])]\n",
    "print(new_df)\n",
    "new_df['target'] = target\n",
    "g1 = sns.PairGrid(new_df, diag_sharey=False)\n",
    "g1.map_lower(sns.scatterplot, hue=new_df['target'], palette='coolwarm', hue_norm=(0, 1))\n",
    "g1.map_diag(sns.histplot, kde=True, color='blue')\n",
    "g1.add_legend()\n",
    "\n",
    "transformed_X = result_pipelines[SELECTED_PIPELINE][idx_to_plot].named_steps['data_transform'].transform(blendshape_training_set_lst[idx_to_plot].X)\n",
    "transformed_X = result_pipelines[SELECTED_PIPELINE][idx_to_plot].named_steps['feature_selection'].transform(transformed_X)\n",
    "new_df = pd.DataFrame(transformed_X, columns=[f\"feature_{i}\" for i in range(len(transformed_X[0]))])\n",
    "target = blendshape_training_set_lst[idx_to_plot].Y.to_list()\n",
    "new_df['target'] = target\n",
    "g2 = sns.PairGrid(new_df, diag_sharey=False)\n",
    "g2.map_lower(sns.scatterplot, hue=new_df['target'], palette='coolwarm', hue_norm=(0, 1))\n",
    "g2.map_diag(sns.histplot, kde=True, color='blue')\n",
    "g2.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "d45f8e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 0       None\n",
      "1       None\n",
      "2       None\n",
      "3       None\n",
      "4       None\n",
      "        ... \n",
      "4843    None\n",
      "4844    None\n",
      "4845    None\n",
      "4846    None\n",
      "4847    None\n",
      "Name: target, Length: 4848, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(target, new_df['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac7f7800",
   "metadata": {},
   "source": [
    "### Call the fit for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors_groups: Dict[str, Dict[str, Any]] = dict()\n",
    "predictors_groups: Dict[str, Dict[str, Any]] = dict()\n",
    "\n",
    "for pipeline in pipelines.values():\n",
    "    selectors, predictors = pipeline.fit_(training_set_list=blendshape_training_set_lst)\n",
    "    selectors_groups[pipeline.pipeline_name] = selectors\n",
    "    predictors_groups[pipeline.pipeline_name] = predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "481207db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataTransformer.transform_X of <__main__.Distance object at 0x7fad1ae96640>>\n"
     ]
    }
   ],
   "source": [
    "print(training_set_transformers[\"distance\"].transform_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "906bccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                           weight   filename\n",
      "32     99   blendShape1.AU_27_MouthStretch        NaN\n",
      "19, 30, 0, 0, 3, 100, 100, 0, 0, 0, 0, 0, 0, 100, 100, 67, 82, 90, 0, 88, 0, 0, 0, 88, 100, 46, 0, 100, 0, 0, 100, 100, 100, 100, 100, 73, 98, 96, 33, 0, 97, 100, 100, 7, 52, 50, 64, 0, \n",
      "[19, 30, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 82, 90, 0, 88, 0, 0, 0, 88, 0, 0, 0, 100, 0, 0, 0, 0, 100, 0, 0, 0, 0, 0, 0, 0, 97, 0, 100, 7, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def get_selected_point_idx(feature_name: str) -> int:\n",
    "    return int(feature_name.split(\"_\")[-1])\n",
    "\n",
    "res = []\n",
    "\n",
    "IDX = 99\n",
    "WEIGHT = 100\n",
    "\n",
    "IMAGE_FILES = [f\"./index{IDX}-weight${WEIGHT}.png\"]\n",
    "# IMAGE_FILE = [\"./test-img-01.jpg\"]\n",
    "name_df = pd.read_csv(\"./blendshapes_name.csv\")\n",
    "print(name_df.loc[name_df['index'] == IDX])\n",
    "\n",
    "\n",
    "selectors = selectors_groups[\"full_distance_chi2_linear_regressor\"]\n",
    "predictors = predictors_groups[\"full_distance_chi2_linear_regressor\"]\n",
    "\n",
    "# for idx, selector in selectors.items():\n",
    "#     selected_features = selector.get_support(indices=True)\n",
    "#     print(idx)\n",
    "#     print(selected_features)\n",
    "\n",
    "# define a function to return a int, in range [min, max],\n",
    "# input is a float.\n",
    "\n",
    "def int_in_given_range(x: float, min: int, max: int) -> int:\n",
    "    if x < min:\n",
    "        return min\n",
    "    elif x > max:\n",
    "        return max\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    ") as face_mesh:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(file)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Print and draw face mesh landmarks on the image.\n",
    "        if not results.multi_face_landmarks:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        arr = []\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for a in face_landmarks.landmark:\n",
    "                arr.append(np.array([a.x, a.y, a.z]))\n",
    "        predict_df = pd.DataFrame([arr], columns=HEADERS[2:])\n",
    "        for pipeline in result_pipelines[\"FullDistance_CustomVarianceThreshold_LinearRegression\"]:\n",
    "            weight = pipeline.predict(predict_df)[0]\n",
    "            print(int_in_given_range(weight, 0, 100), end=\", \")\n",
    "            res.append(int_in_given_range(weight, 0, 100))\n",
    "        print(\"\")\n",
    "        mask = [True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, False, True, True, False, True, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, True, True, False, True, True, False, False, False, False]\n",
    "        for idx, r in enumerate(res):\n",
    "            if not mask[idx]:\n",
    "                res[idx] = 0\n",
    "        print(res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "2522c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "# print(blendshape_training_set_lst[IDX-67].blendshape_name)\n",
    "mask = [True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, False, True, True, False, True, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, True, True, False, True, True, False, False, False]\n",
    "print(len(mask))\n",
    "print(114 - 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f205fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb12b0d5",
   "metadata": {},
   "source": [
    "## Export the ideal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "62477566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selector_group {'67': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '68': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '69': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '70': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '71': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '72': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '73': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '74': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '75': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '76': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '77': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '78': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '79': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '80': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '81': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '82': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '83': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '84': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '85': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '86': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '87': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '88': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '89': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '90': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '91': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '92': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '93': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '94': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '95': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '96': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '97': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '98': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '99': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '100': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '101': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '102': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '103': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '104': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '105': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '106': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '107': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '108': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '109': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '110': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '111': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '112': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '113': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>), '114': SelectKBest(k=7, score_func=<function chi2 at 0x7fad7c3664c0>)}\n",
      "predictors_group {'67': LinearRegression(), '68': LinearRegression(), '69': LinearRegression(), '70': LinearRegression(), '71': LinearRegression(), '72': LinearRegression(), '73': LinearRegression(), '74': LinearRegression(), '75': LinearRegression(), '76': LinearRegression(), '77': LinearRegression(), '78': LinearRegression(), '79': LinearRegression(), '80': LinearRegression(), '81': LinearRegression(), '82': LinearRegression(), '83': LinearRegression(), '84': LinearRegression(), '85': LinearRegression(), '86': LinearRegression(), '87': LinearRegression(), '88': LinearRegression(), '89': LinearRegression(), '90': LinearRegression(), '91': LinearRegression(), '92': LinearRegression(), '93': LinearRegression(), '94': LinearRegression(), '95': LinearRegression(), '96': LinearRegression(), '97': LinearRegression(), '98': LinearRegression(), '99': LinearRegression(), '100': LinearRegression(), '101': LinearRegression(), '102': LinearRegression(), '103': LinearRegression(), '104': LinearRegression(), '105': LinearRegression(), '106': LinearRegression(), '107': LinearRegression(), '108': LinearRegression(), '109': LinearRegression(), '110': LinearRegression(), '111': LinearRegression(), '112': LinearRegression(), '113': LinearRegression(), '114': LinearRegression()}\n"
     ]
    }
   ],
   "source": [
    "selector_group = selectors_groups[\"distance_chi2_linear_regressor\"]\n",
    "print(\"selector_group\", selector_group)\n",
    "for blendshape_i, selector in selector_group.items():\n",
    "    with open(f\"fm2bs_selector_{blendshape_i}.pkl\", \"wb\") as f:\n",
    "        dump(selector, f)\n",
    "predictors_group = predictors_groups[\"distance_chi2_linear_regressor\"]\n",
    "print(\"predictors_group\", predictors_group)\n",
    "for blendshape_i, model in predictors_group.items():\n",
    "    with open(f\"fm2bs_model_{blendshape_i}.pkl\", \"wb\") as f:\n",
    "        dump(model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58e0bbf1",
   "metadata": {},
   "source": [
    "## Draw different parts on mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3dd4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              landmark_0  \\\n",
      "0      [0.4988866150379181, 0.689608097076416, -0.030...   \n",
      "2      [0.49904048442840576, 0.6896460652351379, -0.0...   \n",
      "4      [0.498867005109787, 0.6893705725669861, -0.030...   \n",
      "6      [0.49839678406715393, 0.6897587776184082, -0.0...   \n",
      "8      [0.49848517775535583, 0.6896651983261108, -0.0...   \n",
      "...                                                  ...   \n",
      "19382  [0.4998423457145691, 0.6506761312484741, -0.03...   \n",
      "19384  [0.5001189112663269, 0.6512563228607178, -0.03...   \n",
      "19386  [0.5004903674125671, 0.6509153246879578, -0.03...   \n",
      "19388  [0.5006995797157288, 0.6506898403167725, -0.03...   \n",
      "19390  [0.5005106925964355, 0.6506888270378113, -0.03...   \n",
      "\n",
      "                                              landmark_1  \\\n",
      "0      [0.499955415725708, 0.570995032787323, -0.0658...   \n",
      "2      [0.5003747940063477, 0.570743128657341, -0.065...   \n",
      "4      [0.5005361437797546, 0.5708734691143036, -0.06...   \n",
      "6      [0.5009960532188416, 0.5712557584047318, -0.06...   \n",
      "8      [0.5007985830307007, 0.5709724724292755, -0.06...   \n",
      "...                                                  ...   \n",
      "19382  [0.4998771846294403, 0.5271012485027313, -0.06...   \n",
      "19384  [0.5007592439651489, 0.5273497104644775, -0.06...   \n",
      "19386  [0.5004085302352905, 0.5288893580436707, -0.06...   \n",
      "19388  [0.5008155107498169, 0.5275836437940598, -0.06...   \n",
      "19390  [0.5002802014350891, 0.5273073613643646, -0.06...   \n",
      "\n",
      "                                              landmark_2  \\\n",
      "0      [0.49969348311424255, 0.6269978284835815, -0.0...   \n",
      "2      [0.5000156164169312, 0.6267815232276917, -0.03...   \n",
      "4      [0.500143826007843, 0.6270840167999268, -0.032...   \n",
      "6      [0.5005375742912292, 0.6277957558631897, -0.03...   \n",
      "8      [0.500350296497345, 0.6274120807647705, -0.032...   \n",
      "...                                                  ...   \n",
      "19382  [0.49984803795814514, 0.5919790863990784, -0.0...   \n",
      "19384  [0.5004649758338928, 0.5924004316329956, -0.03...   \n",
      "19386  [0.5000913739204407, 0.5921127796173096, -0.03...   \n",
      "19388  [0.5004478693008423, 0.5912166833877563, -0.03...   \n",
      "19390  [0.49996086955070496, 0.5915396809577942, -0.0...   \n",
      "\n",
      "                                              landmark_3  \\\n",
      "0      [0.4897608757019043, 0.5230487585067749, -0.05...   \n",
      "2      [0.4901176393032074, 0.5227822065353394, -0.05...   \n",
      "4      [0.4903196394443512, 0.5229073762893677, -0.05...   \n",
      "6      [0.49068695306777954, 0.5231821537017822, -0.0...   \n",
      "8      [0.4905293881893158, 0.5228193402290344, -0.05...   \n",
      "...                                                  ...   \n",
      "19382  [0.4897089898586273, 0.4904747009277344, -0.04...   \n",
      "19384  [0.4904252290725708, 0.49075454473495483, -0.0...   \n",
      "19386  [0.4901925027370453, 0.4907197654247284, -0.05...   \n",
      "19388  [0.49049514532089233, 0.48957499861717224, -0....   \n",
      "19390  [0.48990243673324585, 0.48958227038383484, -0....   \n",
      "\n",
      "                                              landmark_4  \\\n",
      "0      [0.4999801218509674, 0.5819868445396423, -0.07...   \n",
      "2      [0.5004010200500488, 0.5817332863807678, -0.07...   \n",
      "4      [0.5005778670310974, 0.5820611715316772, -0.07...   \n",
      "6      [0.5010539889335632, 0.5826898217201233, -0.07...   \n",
      "8      [0.5008506774902344, 0.5821625590324402, -0.07...   \n",
      "...                                                  ...   \n",
      "19382  [0.4997887909412384, 0.547286868095398, -0.068...   \n",
      "19384  [0.5007147789001465, 0.5479310154914856, -0.06...   \n",
      "19386  [0.5004087686538696, 0.5474302768707275, -0.06...   \n",
      "19388  [0.5008102655410767, 0.5465782284736633, -0.06...   \n",
      "19390  [0.5002514123916626, 0.5469406247138977, -0.06...   \n",
      "\n",
      "                                              landmark_5  \\\n",
      "0      [0.4999697506427765, 0.5483439564704895, -0.06...   \n",
      "2      [0.5003584623336792, 0.5480663776397705, -0.06...   \n",
      "4      [0.5005543828010559, 0.5483114123344421, -0.06...   \n",
      "6      [0.5010131001472473, 0.5487724542617798, -0.06...   \n",
      "8      [0.5008184313774109, 0.548300564289093, -0.067...   \n",
      "...                                                  ...   \n",
      "19382  [0.4997155964374542, 0.5144846439361572, -0.06...   \n",
      "19384  [0.5006018877029419, 0.5149707794189453, -0.06...   \n",
      "19386  [0.500365138053894, 0.5147032737731934, -0.065...   \n",
      "19388  [0.5007249116897583, 0.5136935114860535, -0.06...   \n",
      "19390  [0.5001605749130249, 0.5138734579086304, -0.06...   \n",
      "\n",
      "                                              landmark_6  \\\n",
      "0      [0.5002331733703613, 0.46565675735473633, -0.0...   \n",
      "2      [0.5004982948303223, 0.4653382897377014, -0.03...   \n",
      "4      [0.5007191300392151, 0.4652717709541321, -0.03...   \n",
      "6      [0.5010846853256226, 0.4652974009513855, -0.03...   \n",
      "8      [0.5009340047836304, 0.46503645181655884, -0.0...   \n",
      "...                                                  ...   \n",
      "19382  [0.4996647536754608, 0.4351217746734619, -0.03...   \n",
      "19384  [0.5003812909126282, 0.43521249294281006, -0.0...   \n",
      "19386  [0.5003038048744202, 0.4356738328933716, -0.03...   \n",
      "19388  [0.5005266666412354, 0.4342610239982605, -0.03...   \n",
      "19390  [0.49997326731681824, 0.4338957667350769, -0.0...   \n",
      "\n",
      "                                              landmark_7  \\\n",
      "0      [0.4149916172027588, 0.4549860656261444, 0.012...   \n",
      "2      [0.41531455516815186, 0.45511841773986816, 0.0...   \n",
      "4      [0.4156915247440338, 0.4553488492965698, 0.012...   \n",
      "6      [0.4156167507171631, 0.4555164873600006, 0.012...   \n",
      "8      [0.41569584608078003, 0.4553932547569275, 0.01...   \n",
      "...                                                  ...   \n",
      "19382  [0.4160187244415283, 0.42900609970092773, 0.01...   \n",
      "19384  [0.41594430804252625, 0.42851659655570984, 0.0...   \n",
      "19386  [0.4170408248901367, 0.43044009804725647, 0.01...   \n",
      "19388  [0.4167323708534241, 0.4293556809425354, 0.013...   \n",
      "19390  [0.41554635763168335, 0.428039014339447, 0.013...   \n",
      "\n",
      "                                              landmark_8  \\\n",
      "0      [0.5002164244651794, 0.4128425121307373, -0.03...   \n",
      "2      [0.5004242062568665, 0.4126637578010559, -0.03...   \n",
      "4      [0.5006543397903442, 0.4125540852546692, -0.03...   \n",
      "6      [0.5009851455688477, 0.4122222065925598, -0.03...   \n",
      "8      [0.5008617639541626, 0.4117048680782318, -0.03...   \n",
      "...                                                  ...   \n",
      "19382  [0.4992954432964325, 0.38070493936538696, -0.0...   \n",
      "19384  [0.5000582337379456, 0.38038983941078186, -0.0...   \n",
      "19386  [0.5000262260437012, 0.38200461864471436, -0.0...   \n",
      "19388  [0.5001654624938965, 0.3804176449775696, -0.03...   \n",
      "19390  [0.4996132552623749, 0.3802683353424072, -0.03...   \n",
      "\n",
      "                                              landmark_9  ...  \\\n",
      "0      [0.5002545118331909, 0.38348883390426636, -0.0...  ...   \n",
      "2      [0.50045245885849, 0.3833444118499756, -0.0374...  ...   \n",
      "4      [0.5006862282752991, 0.38323521614074707, -0.0...  ...   \n",
      "6      [0.5010197758674622, 0.3828284740447998, -0.03...  ...   \n",
      "8      [0.5008997321128845, 0.3822416067123413, -0.03...  ...   \n",
      "...                                                  ...  ...   \n",
      "19382  [0.4991569519042969, 0.3503901958465576, -0.03...  ...   \n",
      "19384  [0.49998220801353455, 0.35002070665359497, -0....  ...   \n",
      "19386  [0.49995648860931396, 0.3519289493560791, -0.0...  ...   \n",
      "19388  [0.5000681281089783, 0.3502863347530365, -0.03...  ...   \n",
      "19390  [0.49950629472732544, 0.350175142288208, -0.03...  ...   \n",
      "\n",
      "                                            landmark_468  \\\n",
      "0      [0.4344218373298645, 0.4463983178138733, 0.005...   \n",
      "2      [0.43449676036834717, 0.446563184261322, 0.004...   \n",
      "4      [0.43451136350631714, 0.44664710760116577, 0.0...   \n",
      "6      [0.43479686975479126, 0.4466438293457031, 0.00...   \n",
      "8      [0.43465444445610046, 0.44664642214775085, 0.0...   \n",
      "...                                                  ...   \n",
      "19382  [0.43680238723754883, 0.42798808217048645, 0.0...   \n",
      "19384  [0.43962740898132324, 0.42667293548583984, 0.0...   \n",
      "19386  [0.43761146068573, 0.4301758408546448, 0.00564...   \n",
      "19388  [0.4398133158683777, 0.4266367256641388, 0.005...   \n",
      "19390  [0.4394484758377075, 0.42415091395378113, 0.00...   \n",
      "\n",
      "                                            landmark_469  \\\n",
      "0      [0.44659164547920227, 0.4458225667476654, 0.00...   \n",
      "2      [0.4466712772846222, 0.44591307640075684, 0.00...   \n",
      "4      [0.446635365486145, 0.44599148631095886, 0.004...   \n",
      "6      [0.4467504322528839, 0.4460427463054657, 0.004...   \n",
      "8      [0.4466576874256134, 0.4459678530693054, 0.005...   \n",
      "...                                                  ...   \n",
      "19382  [0.44707754254341125, 0.42702195048332214, 0.0...   \n",
      "19384  [0.44955864548683167, 0.42575591802597046, 0.0...   \n",
      "19386  [0.44761836528778076, 0.4294847846031189, 0.00...   \n",
      "19388  [0.44978752732276917, 0.4256644546985626, 0.00...   \n",
      "19390  [0.4496805667877197, 0.4230974018573761, 0.005...   \n",
      "\n",
      "                                            landmark_470  \\\n",
      "0      [0.4342138171195984, 0.4259566068649292, 0.005...   \n",
      "2      [0.43428701162338257, 0.4262278079986572, 0.00...   \n",
      "4      [0.4343115985393524, 0.4263345003128052, 0.004...   \n",
      "6      [0.434626042842865, 0.4262526035308838, 0.0048...   \n",
      "8      [0.43442749977111816, 0.42629122734069824, 0.0...   \n",
      "...                                                  ...   \n",
      "19382  [0.4362736642360687, 0.41095155477523804, 0.00...   \n",
      "19384  [0.4394216537475586, 0.40977486968040466, 0.00...   \n",
      "19386  [0.4372766613960266, 0.41302889585494995, 0.00...   \n",
      "19388  [0.43949559330940247, 0.40970078110694885, 0.0...   \n",
      "19390  [0.4392021894454956, 0.4070435166358948, 0.005...   \n",
      "\n",
      "                                            landmark_471  \\\n",
      "0      [0.42209723591804504, 0.4469475746154785, 0.00...   \n",
      "2      [0.42216211557388306, 0.44721537828445435, 0.0...   \n",
      "4      [0.42222118377685547, 0.4472990036010742, 0.00...   \n",
      "6      [0.42266687750816345, 0.447221040725708, 0.004...   \n",
      "8      [0.42247945070266724, 0.4473083019256592, 0.00...   \n",
      "...                                                  ...   \n",
      "19382  [0.4264843463897705, 0.4289001524448395, 0.006...   \n",
      "19384  [0.42967137694358826, 0.42734578251838684, 0.0...   \n",
      "19386  [0.42749106884002686, 0.43079251050949097, 0.0...   \n",
      "19388  [0.4297461211681366, 0.42740413546562195, 0.00...   \n",
      "19390  [0.4291503429412842, 0.4250407814979553, 0.005...   \n",
      "\n",
      "                                            landmark_472  \\\n",
      "0      [0.4345310926437378, 0.46689558029174805, 0.00...   \n",
      "2      [0.43460068106651306, 0.46698516607284546, 0.0...   \n",
      "4      [0.43460825085639954, 0.4670495092868805, 0.00...   \n",
      "6      [0.4348584711551666, 0.46711158752441406, 0.00...   \n",
      "8      [0.43477410078048706, 0.46708372235298157, 0.0...   \n",
      "...                                                  ...   \n",
      "19382  [0.43733716011047363, 0.4446793496608734, 0.00...   \n",
      "19384  [0.43979620933532715, 0.4433082938194275, 0.00...   \n",
      "19386  [0.43793103098869324, 0.4469854533672333, 0.00...   \n",
      "19388  [0.4400920569896698, 0.44331198930740356, 0.00...   \n",
      "19390  [0.4396285116672516, 0.4410783648490906, 0.005...   \n",
      "\n",
      "                                            landmark_473  \\\n",
      "0      [0.568025529384613, 0.4472395181655884, 0.0033...   \n",
      "2      [0.5683650970458984, 0.4481886327266693, 0.003...   \n",
      "4      [0.5683121681213379, 0.4482775330543518, 0.003...   \n",
      "6      [0.5679852366447449, 0.44803911447525024, 0.00...   \n",
      "8      [0.568098247051239, 0.448199987411499, 0.00395...   \n",
      "...                                                  ...   \n",
      "19382  [0.5647066831588745, 0.4261060357093811, 0.004...   \n",
      "19384  [0.563572883605957, 0.42377129197120667, 0.004...   \n",
      "19386  [0.5633854269981384, 0.42668306827545166, 0.00...   \n",
      "19388  [0.5636528134346008, 0.4264637231826782, 0.004...   \n",
      "19390  [0.5603665709495544, 0.422920823097229, 0.0048...   \n",
      "\n",
      "                                            landmark_474  \\\n",
      "0      [0.5805734395980835, 0.44761812686920166, 0.00...   \n",
      "2      [0.5809231996536255, 0.4484424591064453, 0.003...   \n",
      "4      [0.5811179876327515, 0.4484057128429413, 0.003...   \n",
      "6      [0.5810843706130981, 0.4481080174446106, 0.003...   \n",
      "8      [0.5811120271682739, 0.4482942819595337, 0.003...   \n",
      "...                                                  ...   \n",
      "19382  [0.5760909914970398, 0.42636197805404663, 0.00...   \n",
      "19384  [0.5754857659339905, 0.42410901188850403, 0.00...   \n",
      "19386  [0.5747848153114319, 0.42711472511291504, 0.00...   \n",
      "19388  [0.5753088593482971, 0.42693379521369934, 0.00...   \n",
      "19390  [0.5718539953231812, 0.4230842590332031, 0.004...   \n",
      "\n",
      "                                            landmark_475  \\\n",
      "0      [0.5679535269737244, 0.42792201042175293, 0.00...   \n",
      "2      [0.5682356357574463, 0.42906153202056885, 0.00...   \n",
      "4      [0.5681203007698059, 0.4291161894798279, 0.003...   \n",
      "6      [0.5677794814109802, 0.428642213344574, 0.0039...   \n",
      "8      [0.5679031014442444, 0.4288375973701477, 0.003...   \n",
      "...                                                  ...   \n",
      "19382  [0.5645647048950195, 0.4083057641983032, 0.004...   \n",
      "19384  [0.5633404850959778, 0.4052582085132599, 0.004...   \n",
      "19386  [0.563241183757782, 0.4089701771736145, 0.0049...   \n",
      "19388  [0.5634719133377075, 0.4079926013946533, 0.004...   \n",
      "19390  [0.5600222945213318, 0.40432173013687134, 0.00...   \n",
      "\n",
      "                                            landmark_476  \\\n",
      "0      [0.5554742217063904, 0.44686248898506165, 0.00...   \n",
      "2      [0.555809736251831, 0.44796478748321533, 0.003...   \n",
      "4      [0.5554667115211487, 0.4481864273548126, 0.003...   \n",
      "6      [0.5548190474510193, 0.4480019211769104, 0.003...   \n",
      "8      [0.5550341010093689, 0.4481523633003235, 0.003...   \n",
      "...                                                  ...   \n",
      "19382  [0.5532369017601013, 0.4256054759025574, 0.004...   \n",
      "19384  [0.5515633225440979, 0.4231926202774048, 0.004...   \n",
      "19386  [0.5519402027130127, 0.42601537704467773, 0.00...   \n",
      "19388  [0.5519387722015381, 0.4257737398147583, 0.004...   \n",
      "19390  [0.5488723516464233, 0.4225504994392395, 0.004...   \n",
      "\n",
      "                                            landmark_477  \n",
      "0      [0.5681241750717163, 0.4668073058128357, 0.003...  \n",
      "2      [0.5685176849365234, 0.4675838351249695, 0.003...  \n",
      "4      [0.568515956401825, 0.46769779920578003, 0.003...  \n",
      "6      [0.568195641040802, 0.46770578622817993, 0.003...  \n",
      "8      [0.5683033466339111, 0.46783697605133057, 0.00...  \n",
      "...                                                  ...  \n",
      "19382  [0.5648030042648315, 0.44341057538986206, 0.00...  \n",
      "19384  [0.5637545585632324, 0.4417971074581146, 0.004...  \n",
      "19386  [0.5634795427322388, 0.4438058137893677, 0.004...  \n",
      "19388  [0.5637927651405334, 0.44436702132225037, 0.00...  \n",
      "19390  [0.5606772899627686, 0.4410148859024048, 0.004...  \n",
      "\n",
      "[9696 rows x 478 columns]\n"
     ]
    }
   ],
   "source": [
    "half_X = multitask_X.iloc[0::2, ::]\n",
    "half_Y = multitask_Y.iloc[0::2, ::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63a927b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_blendshape \u001b[39m=\u001b[39m \u001b[39m2424\u001b[39m\n\u001b[0;32m----> 2\u001b[0m distance_X \u001b[39m=\u001b[39m FullDistance()\u001b[39m.\u001b[39;49mtransform(half_X)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m((distance_X\u001b[39m.\u001b[39miloc[:,\u001b[39m296\u001b[39m]))\n\u001b[1;32m      4\u001b[0m Y \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mFullDistance.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     34\u001b[0m normalised_distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(max_distance)\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m _, landmark \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(row):\n\u001b[0;32m---> 36\u001b[0m     distance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(landmark \u001b[39m-\u001b[39;49m middle_point)\n\u001b[1;32m     37\u001b[0m     new_row\u001b[39m.\u001b[39mappend(distance)\n\u001b[1;32m     38\u001b[0m \u001b[39m## distance_X.loc[i] = [distance / normalised_distance for distance in new_row] # type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/fyp/lib/python3.8/site-packages/numpy/linalg/linalg.py:2357\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_norm_dispatcher\u001b[39m(x, \u001b[39mord\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2354\u001b[0m     \u001b[39mreturn\u001b[39;00m (x,)\n\u001b[0;32m-> 2357\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[1;32m   2358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnorm\u001b[39m(x, \u001b[39mord\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2359\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2360\u001b[0m \u001b[39m    Matrix or vector norm.\u001b[39;00m\n\u001b[1;32m   2361\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \n\u001b[1;32m   2507\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2508\u001b[0m     x \u001b[39m=\u001b[39m asarray(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_blendshape = 2424\n",
    "distance_X = FullDistance().transform(half_X)\n",
    "print((distance_X.iloc[:,296]))\n",
    "Y = []\n",
    "for row in half_Y.iterrows():\n",
    "    Y.append(row[1].values[0][0])\n",
    "print(Y)\n",
    "print(\"Done\")\n",
    "colors = [\"red\",\"blue\",\"yellow\",\"purple\"]\n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(distance_X.iloc[i*n_blendshape:(i+1)*n_blendshape, 296], Y[i*n_blendshape:(i+1)*n_blendshape], c=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7633c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,) 478\n"
     ]
    }
   ],
   "source": [
    "n_targets = multitask_Y.iloc[0].values[0].shape\n",
    "n_features = distance_X.shape[1]\n",
    "fig, axes = plt.subplots(nrows=n_targets, ncols=n_features, figsize=(15, 8))\n",
    "\n",
    "for i in range(n_targets):\n",
    "    for j in range(n_features):\n",
    "        axes[i, j].scatter(X[:, j], Y[:, i], alpha=0.5)\n",
    "        axes[i, j].set_xlabel(f\"Feature {j+1}\")\n",
    "        axes[i, j].set_ylabel(f\"Target {i+1}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "521bcd0e3998f6b974b57d228f286ddc21c2fd1fe5bddf49bde57518d066147d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
